{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment with Flair\n",
    "\n",
    "Flair offers models that we can use out-of-the-box. One of those is the English sentiment model, which we will learn how to use here.\n",
    "\n",
    "First, we need to make sure Flair has been installed, we do this in our CLI with:\n",
    "\n",
    "```\n",
    "pip install flair\n",
    "```\n",
    "\n",
    "Flair uses PyTorch/TensorFlow in under the hood, so it's essential that you also have one of the two libraries (or both) installed. There are a few steps in applying sentiment analysis, these are:\n",
    "\n",
    "1. Initializing the model.\n",
    "\n",
    "2. Tokenizing input text.\n",
    "\n",
    "3. Processing with the model.\n",
    "\n",
    "4. Format the outputs.\n",
    "\n",
    "We then load the English sentiment model like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-12 16:44:15,217 https://nlp.informatik.hu-berlin.de/resources/models/sentiment-curated-distilbert/sentiment-en-mix-distillbert_4.pt not found in cache, downloading to /tmp/tmpf7974vl3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 265512723/265512723 [00:31<00:00, 8346696.92B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-12 16:44:47,785 copying /tmp/tmpf7974vl3 to cache at /home/tola/.flair/models/sentiment-en-mix-distillbert_4.pt\n",
      "2022-11-12 16:44:47,884 removing temp file /tmp/tmpf7974vl3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-12 16:44:49,279 loading file /home/tola/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bf817f9cc79405895967c0022233e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf258021a46f46d4935f496511465cc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e1c1e8ebdf84db2b023a461ede9d35e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e28e13cb28f4f7d8ee3efeabe860ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import flair\n",
    "model = flair.models.TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first time this `load` method is run for the `'en-sentiment'` model the model will be downloaded. After this, the model is initialized. The `en-sentiment` model is a distilBERT model fitted with a classification head that outputs two classes - negative and positive.\n",
    "\n",
    "Our next step is to tokenize input text. For this we use the Flair `Sentence` object, which we initialize by passing our text into it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-12 17:51:17,059 loading file /home/tola/.flair/models/sentiment-en-mix-distillbert_4.pt\n"
     ]
    }
   ],
   "source": [
    "import flair\n",
    "model = flair.models.TextClassifier.load('en-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"I like you!\"  # we are expecting a confidently positive sentiment here\n",
    "\n",
    "# sentence = flair.data.Sentence(text)\n",
    "\n",
    "# sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"think i was becoming legit annoyed at the delorean comments more than anything else\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"think i was becoming legit annoyed at the delorean comments more than anything else\"  # we are expecting a confidently positive sentiment here\n",
    "\n",
    "sentence = flair.data.Sentence(text)\n",
    "\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we now have the Flair `Sentence` object, which contains our text, alongside a *tokenized* version of it (each word/punctuation character is an individual token):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'think i was becoming legit annoyed at the delorean comments more than anything else'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.to_tokenized_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to process our tokenized inputs through out distilBERT classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `predict` method doesn't output our prediction, instead the predictions are added to our `sentence`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_text(txt):\n",
    "    sentence = flair.data.Sentence(txt)\n",
    "    sentence.to_tokenized_string()\n",
    "    model.predict(sentence)\n",
    "    return(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"chasing down a Civic LX and pulling up next to a grandpa as i blast tokyo drift music\" → POSITIVE (0.9969)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyze_text(\"chasing down a Civic LX and pulling up next to a grandpa as i blast tokyo drift music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"think i was becoming legit annoyed at the delorean comments more than anything else\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that we are predicting a `POSITIVE` sentiment with a probability of `0.9933`, which is **very** confident as expected. Let's repeat the process with something more negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"think i was becoming legit annoyed at the delorean comments more than anything else\" → NEGATIVE (0.9943)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = \"I hate it when I'm not learning\"\n",
    "sentence = flair.data.Sentence(text)\n",
    "model.predict(sentence)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we correctly predict a `NEGATIVE` sentiment. Finally, we will typically want to extract our predictions and format them into the format that we need for our own use-case (for example plotting sentiment over time). Let's take a look at how we do that.\n",
    "\n",
    "The `Sentence` object provides us with a method called `get_labels`, we can use this to extract our sentiment prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sentence: \"think i was becoming legit annoyed at the delorean comments more than anything else\"'/'NEGATIVE' (0.9943)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.get_labels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this method we actually get a list, which contains our label object. To access each item in the list we need to dig a little deeper. We first access the label object by accessing the *0th* index of our list. Flair `Label` objects contain two attributes, `score` and `value` - which contain our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sentence: \"think i was becoming legit annoyed at the delorean comments more than anything else\"'/'NEGATIVE' (0.9943)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.get_labels()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9942528605461121"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.get_labels()[0].score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NEGATIVE'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.get_labels()[0].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can access the label values directly (although not recommended) like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9942528605461121, 'NEGATIVE')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.labels[0].score, sentence.labels[0].value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
